\subsection{Suchindexe}
\label{sec:search}

Mit dem Begriffen ``Suche'' und ``Suchmaschinen'' werden umgangssprachlich zahlreiche Methoden des  \ac{IR} beschrieben, die durch Internet-Dienste wie Google\footnote{siehe: http://www.google.com} im Alltag vieler Menschen präsent sind. Im \acs{IR} wird eine ``Suche'' formal als die Extraktion von Informationen aus einer Menge unstrukturierter Daten definiert. Innerhalb eines \acs{IR} Systems liegen die Daten in Form von \textit{Dokumenten} (Texte, Bilder, Videos) vor. Bei der Benutzung des \acs{IR} Systems formuliert der Nutzer seinen \textit{Informationsbedarf} mit Hilfe von \textit{Anfragen}. Dokumente werden als \textit{relevant} bezeichnet, wenn die darin enthaltene Information dem Bedarf des Nutzers genügt. Im weiteren Sinne umfasst \acs{IR} zudem das Filtern, Klassifizieren und Verarbeiten der gefundenen Dokumente.  \citep{Manning2008}

Die durch den Nutzer formulierten Anfragen sind dabei, im Gegensatz zu Anfragen an strukturierte Datenbanken, nicht zwingend eindeutig. Sucht der Nutzer etwa nach ``Fantasy Buch'', kann ``Harry Potter'' in den Augen des Nutzers ein relevantes Dokument sein, ohne dass die Begriffe ``Fantasy'' oder ``Buch'' explizit darin vorkommen. \\ \\%http://nlp.stanford.edu/IR-book/pdf/04const.pdf

\subsubsection{Indexbildung} \label{sec:indexcreation}

Da es bei einer großen Anzahl von vorhandenen Dokumenten sehr ineffizient wäre, wenn bei jeder Anfrage jedes Dokument geprüft werden müsste, wird ein \textit{invertierter Index} verwendet um Informationen zu Dokumenten abzubilden. Die Indexierung erfolgt dabei in vier Schritten, welche für zwei Beispieldokumente\footnote{Ausschnitte aus ``Julius Caesar'' von William Shakespeare} wie folgt verlaufen:

\begin{enumerate}
\item Sammeln aller Dokumente und Zuordnung von eindeutigen Bezeichnern (\textit{docID}) \\ { \scriptsize ..., 20:\fbox{Friends, Romans, countrymen}, 21:\fbox{So let it be with Caesar.},... }
\item Extraktion der Dokumentenmerkmale (z.B. Wörter) \\ { \scriptsize \fbox{Friends} \fbox{Romans} \fbox{countrymen} \fbox{Caesar} }
\item Normalisierung der Merkmale (z.B. Reduzierung auf Wortstämme) \\ { \scriptsize \fbox{friend} \fbox{roman} \fbox{countryman} \fbox{caesar} }
\item Indexbildung, Zuordnung der \textit{docID} zu den Einträgen der sortierten Merkmalsliste
{ \scriptsize \begin{tabular}[b]{lcl}
 \fbox{caesar} & $\longmapsto$ & \fbox{ 21 } \\
 \fbox{countryman} & $\longmapsto$ & \fbox{ 11 }\fbox{ 20 } \\
 \fbox{friend} & $\longmapsto$& \fbox{ 15 }\fbox{ 20 }\fbox{ 73 }\\
 \fbox{roman}& $\longmapsto$ & \fbox{ 20 }\fbox{ 32 }\\ 
 ... & &
\end{tabular} }
\end{enumerate}

Die in den Schritten 1 bis 3 durchgeführten Verarbeitungsschritte sind immer abhängig von dem gegebenen Kontext. Entspricht z.B. im herkömmlichen Verständnis jede Datei einem Dokument, so muss bei der Verarbeitung des MBox-Formates\footnote{siehe RFC 4155 - http://tools.ietf.org/rfc/rfc4155.txt} jede Zeile einer Datei als einzelnes Dokument gesehen werden. Auch die Wahl einer geeigneten Methode zur Wortstammbildung (auch ``Stemming'') und das Filtern von nicht relevanten Wörtern mit Hilfe sog. ``Stopwörter'' hängt vom gegebenen Kontext ab. \citep[Kap. 2]{Manning2008}. \\ \\

Formuliert der Nutzer nun seine Anfrage, durchläuft diese ebenfalls die Schritte 2 und 3 bevor Dokumente mit Hilfe des Index gefunden werden können. Besteht die Anfrage aus mehreren Bestandteilen, wird die Liste der relevanten Dokumente aus der Schnittmenge der für die einzelnen Teile gefundenen Dokumentenmengen gebildet. Ergänzend existieren verschiedene Erweiterungen des invertierten Index. Diese ermöglichen beispielsweise noch effizienter in sehr großen Dokumentenbeständen suchen zu können, die Position der Merkmale innerhalb des Dokumentes nutzbar zu machen oder den Umfang des Index einzuschränken. Sie werden u.a. in \citep[Kap. 3,4,5]{Manning2008} beschrieben und hier zur Wahrung des Umfangs ausgelassen.

\subsubsection{Relevanzberechnung}\label{sec:searchrelevance}\label{tfidf}
Die reine Generierung einer Dokumentenliste als Ergebnis der Anfrage genügt vor allem bei großen Dokumentenbeständen nicht. Mögliche Methoden, um die Listen  entsprechend der Relevanz eines Dokumentes zu sortieren, sind zum einen das \textit{TF-IDF Maß} und bei untereinander verknüpften Dokumenten der \textit{PageRank}.

\paragraph{TF-IDF Maß} Zur Bildung dieses Maßes wird die Relevanz des Terms $i$ innerhalb des Dokumentes $d$ und die Relevanz des Terms innerhalb des gesamten Dokumentenbestands ins Verhältnis gesetzt.
\begin{align}
\text{tf}(i, d) & = \frac{\text{freq}(i, d)}{\text{max}_{z \in Z}(\text{freq}(z, d))} \\
\text{idf}(i) & = \log{\frac{N}{n(i)}} \\
\text{tf-idf}(i, d) & = \text{tf}(i ,d) \ast \text{idf}(i) \label{form:tfidf}
\end{align}

Um die Relevanz eines Terms bezüglich eines Dokumentes abzubilden, wird die relative Häufigkeit mit der der Term innerhalb des Dokumentes vorkommt, genutzt. Die sog. \textit{Termfrequenz} bildet sich entsprechend aus dem Verhältnis der Anzahl der Vorkommen des Terms innerhalb des Dokumentes ($freq(i,j)$) zur maximalen Anzahl aller anderen Terme $Z$ im Dokument. Mit Hilfe der inversen Dokumentenfrequenz (\acs{IDF}) wird die \acf{TF} eines Terms abgewertet, wenn dieser in nahezu jedem Dokument vorkommt und aufgewertet, wenn er nur selten genutzt wird. Die \acs{IDF} wird aus dem Verhältnis der Gesamtdokumentenzahl $N$ zur Anzahl der Dokumente die den Term $i$ enthalten ($n(i)$), gebildet.

Das \textit{TF-IDF Maß} bildet sich entsprechend Formel (\ref{form:tfidf}) aus dem Produkt der beiden Teilmaße und ist:
\begin{itemize}
\item hoch: wenn der Term $i$ oft in einer kleinen Anzahl von Dokumenten vorkommt und sich gut zur Unterscheidung von Dokumenten eignet
\item niedrig: wenn der Term selten im Dokument vorkommt oder in vielen verschiedenen Dokumenten genutzt wird
\item minimal: wenn der Term in nahezu jedem Dokument vorkommt
\end{itemize}

Die Summe der Relevanz eines Dokuments bezüglich aller Teilterme der Anfrage $q$ bildet dann die Grundlage, um die erzeugte Dokumentenliste zu sortieren.\citep{Manning2008} 
\begin{align}
\text{score}(q,d) & = \sum_{t \in q}{\text{tf-idf}(t,d)}  \label{form:docscore}
\end{align}

\paragraph{PageRank} Sind die Dokumente untereinander verknüpft, kann man auch die Popularität eines Dokumentes zur Grundlage der Anordnung in der Ergebnisliste machen. Diese Popularität wird i.d.R. in Form des PageRank ausgedrückt. Dieser korreliert mit der Wahrscheinlichkeit, dass ein zufällig über den Verknüpfungsgraphen laufender Nutzer ein bestimmtes Dokument erreicht. Dokumente, auf die häufig verwiesen wird, besitzen demnach einen hohen PageRank und Verweise von populären Dokumenten üben einen großen Effekt auf den PageRank der verknüpften Dokumente aus.
\begin{align}
R(d) & = c \sum_{v \in B_d}{\frac{R(v)}{N_v}} + cE(d) \label{form:pagerank}
\end{align}

Berechnet wird der PageRank $R$ eines Dokumentes $d$ mit Hilfe der Formel (\ref{form:pagerank}). Der Faktor $c < 1$ dient dabei zur Abstraktion des Verlustes durch Seiten ohne ausgehende Verweise. Der Vektor $E$ bildet die Wahrscheinlichkeit ab, dass der Nutzer seinen Pfad unterbricht und zufällig bei Dokument $d$ fortsetzt.\citep{pagerank,Manning2008}

\subsubsection{Personalisierung}\label{sec:personalresultstheorie}

Die Personalisierung der Dokumentenlisten kann über verschiedene Wege erreicht werden. Der Offensichtliche ist, die der Anfrage entsprechende Dokumentenliste anhand der Präferenzen eines Nutzerprofils umzusortieren. Eine weitere Möglichkeit ist, die durch den Nutzer formulierte Anfrage vor der eigentlichen Verarbeitung mit Informationen des Nutzerprofils zu erweitern.

Die erste Methode wird zum Beispiel in \citep{Durao12} beschrieben. Um die Dokumentenliste zu personalisieren, wird zunächst ein schlagwortbasiertes Nutzerprofil aufgebaut, welches die bevorzugten Schlagworte $t \in T_u$ in Bezug auf verschiedene Faktoren $F$ und deren relative Frequenz $T_f \subset T_u$ beinhaltet. Die Gewichtung der Faktoren untereinander wird durch $\alpha_f$ realisiert. Zusätzlich werden auch zu jedem Dokument entsprechende Tags $T_d$ gepflegt, so dass die Ähnlichkeit von Nutzerprofil und Dokument mit Hilfe der Kosinus-Ähnlichkeitsmaßes (siehe Abschnitt \ref{sec:cossim}) berechnet werden kann. Da die initiale Dokumentenliste anhand des TF-IDF Maßes sortiert wird, ergibt sich die endgültige Bewertung für den Nutzer $u$ aus:  (vgl. \citep{Durao12})
\begin{align}
\text{score}(q,d,u) & = \text{score}_{\text{tf-idf}}(q,d) * \sum_{f \in |F|}{\alpha_f \frac{\overrightarrow{T_d} \overrightarrow{T_f}}{|\overrightarrow{T_d}| |\overrightarrow{T_f}|}} \label{form:personalresultstheorie}
\end{align}

Die Anpassung der Anfrage vor der Verarbeitung durch die Suche wird zum Beispiel in \citep{Boughareb11} genutzt. Das Nutzerprofil wird dabei aus der Liste aller vorangegangenen Suchanfragen $Q_s$ gebildet. Formuliert der Nutzer eine neue Anfrage, so wird diese um weitere relevante Schlüsselwörter aus ähnlichen Anfragen ergänzt. Zur Bestimmung der Ähnlichkeit zwischen Suchanfragen wird ebenfalls das Kosinus-Ähnlichkeitsmaß (siehe Abschnitt \ref{sec:cossim}) genutzt. Die Relevanz der Schlüsselwörter wird an deren Dokumentenfrequenz (vgl. Abschnitt \ref{sec:searchrelevance}) innerhalb des Nutzerprofils $Q_s$ bestimmt. Die Verarbeitung der Suche geschieht dann mit der erweiterten Anfrage wie in den vorangegangenen Abschnitten beschrieben.

In \citep{smyth05a} wird gezeigt, dass die Erweiterung der Anfrage auch ohne explizites Nutzerprofil zur Verbesserung der Relevanz der gefundenen Ergebnisse beitragen kann. Realisiert wird dies auf der Grundlage von kollaborativen- bzw. gruppenbasierten Methoden (vgl. Abschnitt \ref{sec:cf_overview} u. \ref{sec:cbf_overview}). Die zur Erweiterung genutzten ähnlichen Anfragen werden dabei aus der für die gesamte Suchmaschine genutzten Datenbasis gewonnen. Dies hat zudem den Vorteil, dass auch Nutzer ohne umfangreiches Nutzerprofil von den erweiterten Bewertungskriterien profitieren, allerdings ist der Grad der Personalisierung durch den Verzicht auf ein Nutzerprofil eingeschränkt. Auch die notwendige Homogenität der Nutzergruppe einer Plattform kann nicht beliebig auf andere übertragen werden. \citep{smyth05a}

Auch der PageRank ermöglicht die personalisierte Sortierung der Dokumentenlisten. Wählt man für den Vektor $E$ in Formel (\ref{form:pagerank}) nutzerspezifische Absprungwahrscheinlichkeiten so wird, wie in \citep{pagerank} beschrieben, der resultierende PageRank den Präferenzen des Nutzers entsprechen. Da eine vollständige Berechnung des PageRank pro Nutzer innerhalb großer Dokumentenbestände sehr unpraktisch ist, wurden zudem verschiedene Erweiterungen untersucht. In \citep{ilprints596} werden mögliche Ansätze beschrieben. Im Kern aller Ansätze werden mehrere verschiedene ``featurebasierte'' PageRank-Werte pro Dokument berechnet. Während der Anfrage werden diese vorberechneten Werte entsprechend des Nutzerprofils gewichtet. \citep{ilprints596} %\todo[color=green]{ggf. um Beispiel ergänzen}

%Radlinski11 - für Qualitätsmaße d. Suchen \\
%Durao11 - Personalisierung v. Suchen
