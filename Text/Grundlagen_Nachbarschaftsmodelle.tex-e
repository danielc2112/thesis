\subsubsection{Nachbarschaftsmodelle}\label{sec:neighborhoods}

\paragraph{Nutzer-basierte Modelle} Geht man nun davon aus, dass ähnliche Nutzer auch in der Zukunft eine ähnliche Meinung zu einem Element haben werden, kann für einen Nutzer $u$ aus den vorliegenden Bewertungen ähnlicher Nutzer $\mathcal{N}_i(U)$ eine Bewertung für ein Element $i$ voraus gesagt werden ($pred(u,i)$). Die dabei in Betracht gezogenen anderen Nutzer werden auch als ``Nachbarschaft'' des Nutzers bezeichnet. Da diese zudem i.d.R. auf eine bestimmte Größe $k$ oder einen bestimmten Ähnlichkeits-Schwellwert limitiert ist, wird die Methode als \textit{k--nearest-neighbors} (k-NN) bezeichnet.

Um Empfehlungen für einen Nutzer aus den in Tabelle \ref{tab:user-item-ratings} gezeigten Ausgangsdaten abzuleiten, wird mit Hilfe der schon vorliegenden Ratings zunächst die Ähnlichkeit dieses Nutzers zu anderen berechnet (siehe Tabelle \ref{tab:user-user-sim}). Um $pred(u,i)$ aus diesen abzuleiten, werden die Ratings anderer Nutzer für dieses Element $r_{v,i}$ entsprechend der Ähnlichkeit zwischen den Nutzern aufsummiert und normiert:
\begin{align}
pred(u,i) & = \frac{ \sum_{v \in \mathcal{N}_i(U)} sim(u, v)*r_{v,i}}{ \sum_{v \in \mathcal{N}_i(U)} sim(u,v) } \label{form:calcpred}
\end{align}
Wie \citep{Herlocker:2002:EAD:593967.594047} zeigen, muss zudem ein weiterer Unterschied zwischen einzelnen Nutzern in Betracht gezogen werden. Auch wenn Nutzer generell ähnliche Interessen bzw. Meinungen haben, so kann es durchaus sein, dass Mittelwert und Varianz der Ratings dieser Nutzer sehr verschieden sind. Diese Gewichtung von Rating-Mittelwert $\overline{r_u}$ und der Varianz  $\sigma_u$ der Nutzer, wird zu diesem Zweck in den erweiterten Formeln (\ref{form:calcmeanpred}) und (\ref{form:calcmeanvarpred}) einbezogen. \citep{hb_04,Huete:2012:UPA:2206442.2206675}
\begin{table}[ht]
  \centering
\begin{minipage}[b]{4in}
  \begin{tabular}{ | l || c | c | c | c | c | c | c | }
    \hline
           & User2 & User3 & User4 & User5 \\ \hline
User1 &    0.203 &	0.286 &	0.667 & 0.472 \\
    \hline
  \end{tabular}
  \caption{\footnotesize Aus Tabelle \ref{tab:user-item-ratings} mit der euklidischen Distanz abgeleiteter Ähnlichkeitsvektor für User1 { \scriptsize (eigene Abbildung)}}
  \label{tab:user-user-sim}
\end{minipage}
\end{table}
\begin{align}
pred(u, i) & = \overline{r_u} + \frac{ \sum_{v \in \mathcal{N}_i(U)} sim(u, v)*(r_{v,i}-\overline{r_v}) } { \sum_{v \in \mathcal{N}_i(U)} sim(u,v) } \label{form:calcmeanpred} \\
pred(u, i) & = \overline{r_u} + \sigma_u \frac{ \sum_{v \in \mathcal{N}_i(U)} sim(u, v)*\frac{r_{v,i}-\overline{r_v}}{\sigma_v} } { \sum_{v \in \mathcal{N}_i(U)} sim(u,v) } \label{form:calcmeanvarpred}
\end{align}

\paragraph{Element-basierte Modelle} Neben der Bestimmung von ähnlichen Nutzern, kann mit den in der \textit{User-Item} Matrix vorliegenden Daten auch die Ähnlichkeit von Elementen bestimmt werden. Die Ähnlichkeiten bzw. Nachbarschaften der Elemente $\mathcal{N}_u(I)$ zu anderen kann dann, analog zu Formel (\ref{form:calcpred}), wie folgt zur Voraussage der Bewertungen genutzt werden:
\begin{align}
pred(u,i) & = \frac{ \sum_{j \in \mathcal{N}_u(I)} sim(i,j)*r_{u,j}}{ \sum_{j \in \mathcal{N}_u(I)\mathcal{N}_i(U)} sim(i,j) } \label{form:calcpreditem}
\end{align}
\begin{table}[ht]
  \centering
\begin{minipage}[b]{4in}
  \begin{tabular}{ | l || c | c | c | c | c | c | c | }
    \hline
           & Item1 & Item2 & Item3 & Item5 & Item6 & Item7 \\ \hline
Item4 &    0.387 &	0.472 &	0.204 & 0.586 & 0.667 & 0.500 \\
    \hline
  \end{tabular}
  \caption{\footnotesize Aus Tabelle \ref{tab:user-item-ratings} mit der euklidischen Distanz abgeleiteter Ähnlichkeitsvektor für Item4 { \scriptsize (eigene Abbildung)}}
  \label{tab:item-item-sim}
\end{minipage}
\end{table}
Wie bei den nutzerbasierten Modellen sollte auch hier der Einfluss verschiedener Bewertungsmittelwerte und Varianzen ausgeglichen werden. Dies geschieht analog zu Formel (\ref{form:calcmeanpred}) und (\ref{form:calcmeanvarpred}).
%\todo[color=green]{Quelle das ``Normalisierung'' auch bei item-item relevant ist}
% \todo[color=green]{Ergebnisse der Rechnung einfügen}

Für die Abwägung zwischen nutzer- und elementbasierten Methoden gibt \citep{hb_04} die folgenden Kriterien an:

\begin{itemize}
\item \textit{Genauigkeit} - Abhängig von der Menge der Nutzer und Elemente im System schwankt die Zuverlässigkeit der Nachbarschaften. Ist die Anzahl der Nutzer im System größer als die der Elemente, so kann davon ausgehen werden, dass elementbasierte Methoden kleinere aber zuverlässigere Nachbarschaften für die einzelnen Elemente produzieren und damit bessere Ergebnisse liefern und umgekehrt (vgl. auch \citep{Huete:2012:UPA:2206442.2206675} u. \citep{Herlocker:2002:EAD:593967.594047})
\item \textit{Effizienz} - Das Verhältnis von Nutzern und Elementen beeinflusst auch den Umfang der notwendigen Berechnung bei der Bestimmung von Nachbarschaften. \citep{linden03} zeigt zum Beispiel, dass die Grenzen der Skalierbarkeit schnell erreicht werden, wenn die Zahl der Nutzer die der Elemente stark überschreitet.
\item \textit{Stabilität} - Die Änderungshäufigkeit in der Menge der bewerteten Elemente bzw. die Fluktuation der Nutzer beeinflusst, wie stabil Ähnlichkeiten sind. Ist die gewählte Basis ausreichend stabil, können Ähnlichkeiten vorberechnet werden.
\item \textit{Erklärbarkeit} - Die der Berechnung von elementebasierten Ähnlichkeiten zugrunde liegenden Elemente lassen sich leicht zur Erklärung der Ergebnisse nutzen und ermöglichen ggf. eine darauf basierende Interaktion mit dem Nutzer. Bei nutzerbasierten Modellen ist dies i.d.R. auch aus Gründen des Datenschutzes erheblich schwerer.
\item \textit{Zufälligkeit} - Die im ersten Punkt beschriebene Genauigkeit führt i.d.R dazu, dass bei elementbasierten Modellen oft weniger überraschende Vorschläge erzeugt werden. Bezieht man bei nutzerbasierten Modelle nur wenige Nachbarn zur Erzeugung der Vorschläge ein, ist die Wahrscheinlichkeit eines unerwarteten Ergebnisses höher. (vgl. Abschnitt \ref{sec:richgetsricher})
\end{itemize}

\paragraph{Nachbarschaftsgrößen} Unabhängig von der Methodenwahl muss die Größe der betrachteten Nachbarschaft $k$ begrenzt werden. Werden feste Werte gewählt, so sind Größen zwischen 20 und 50 (vgl. \citep{Herlocker:2002:EAD:593967.594047}) üblich. Kleinere Nachbarschaften werden wegen ihrer Anfälligkeit für Ausreißer nicht empfohlen, bei größeren wiederum steigt i.d.R. die Fehlerquote.

Neben festen Werten wird häufig alternativ die Wahl eines Ähnlichkeitsschwellwertes vorgeschlagen. Dabei werden alle Nachbarn einbezogen, deren Ähnlichkeit einen Maximalabstand nicht überschreitet. Da die Wahl des Schwellwertes nicht nur Auswirkungen auf den Umfang der Nachbarschaft, sondern auch auf die Abdeckung der berechenbaren Bewertungsvorhersagen hat, wird i.d.R (vgl. \citep{Herlocker:2002:EAD:593967.594047, Herlocker:1999:AFP:312624.312682}) von der alleinigen Verwendung abgeraten.

Die Wahl der konkreten Größe ist bei beiden Methoden zudem in jedem Fall ein Kompromiss zwischen Genauigkeit, Zufälligkeit und Effizienz.

\paragraph{Vorteile von Nachbarschaftsmodellen} Dass zum Vergleich mit anderen Methoden, keine langwierige Trainingsphase notwendig ist, ist \todo{ist, ist} ebenso wie die leichte Nachvollziehbarkeit der  Methodik ein Vorteil von Nachbarschaftsmodellen. Die Möglichkeit, Empfehlungen durch eine Erklärung zu ergänzen, ist ein weiterer Vorteil, dem bei der Bildung des Nutzervertrauens besonders viel Gewicht zukommt (vgl. \citep{hb_15}). Die Stabilität der zugrunde liegenden Ähnlichkeitsmatrizen und der Effizienzgewinn durch die mögliche Vorberechnung der Nachbarschaften sind zudem bei großen Systemen von Vorteil (vgl. \citep{linden03}).\citep{hb_04} %\todo[color=green!40]{Weiterführend: Regression vs. Classification aus HB04 evt. ergänzen}
%Sarwar01  -> Item-base zu bevorzugen \\
%\citep{bogers09} -> User-Based zu bevorzugen \\
%Prediction-accuracy with in \citep{Huete:2012:UPA:2206442.2206675}
