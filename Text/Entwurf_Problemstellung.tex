\newpage
\subsection{Problemstellungen}

Bei der Kombination von Suchindexen (vgl. Abschnitt \ref{sec:search}) und kollaborativen Empfehlungsdiensten (vgl. Abschnitt \ref{sec:filtermethods}) treffen zwei Techniken mit verschiedenen Kernaufgaben aufeinander. Den möglichen Nutzen der daraus entstehenden Resultate zeigen die im vorangegangenen Abschnitt beschriebenen Anwendungsfälle. Die dafür zu lösenden Schwierigkeiten und mögliche Lösungsansätze werden im Folgenden beschrieben.

\subsubsection{Skalierbarkeit}\label{sec:scale2}

Beim Aufbau eines  Gesamtsystems, welches den beschriebenen Leistungsanforderungen genügt, muss jeder Bestandteil Möglichkeiten zur Skalierung bieten. D.h. nicht nur die Komponenten der Datenhaltung und Datenverarbeitung sollten diesbzgl. betrachtet werden, sondern auch die Kommunikationswege zwischen ihnen. Wie die in Abschnitt \ref{sec:scale} zusammengefassten Grundlagen zeigen, existieren verschiedene Ansätze zur Skalierung einzelner Bestandteile. Die Ableitung einer einheitlichen Architektur ist deshalb ein weiteres zu lösendes Problem.

Ein möglicher Lösungsansatz zum Aufbau eines skalierbaren Systems zur allgemeinen Datenanalyse wird in \citep{Lin2012} beschrieben. Auf Basis von einfach zu beschreibenden \textit{MapRecude}-Programmen werden in einem \acs{GFS} gehaltene Daten direkt verarbeitet und analysiert. Die Architektur eines skalierbaren und für den Nutzer möglichst unsichtbaren Logging-Systems, sowie die daran gestellten Anforderungen, beschreibt \citep{netflix2012} am Beispiel der Netflix-Plattform\footnote{siehe: http://netflix.com}. In beiden Fällen geschieht die Verarbeitung der Daten asynchron. Vom Nutzer erzeugte Daten bewirken nicht sofort eine Aktualisierung des Gesamtsystems. Vielmehr werden die Daten in beiden Fällen zunächst gesammelt und nachgelagert verarbeitet. Am Beispiel der Google-News\footnote{siehe: http://news.google.com/} Architekturbeschreibung zeigt \citep{Das07}, dass dies auch in sehr kurzen Zeitintervallen für eine sehr große Nutzerzahl möglich ist. Neben der asynchronen Datenverarbeitung wird hier zudem gezeigt, wie die Methoden der horizontalen Skalierung (vgl. Abschnitt \ref{sec:sharding}) einfließen können.

Die Möglichkeiten der Vorberechung von Empfehlungs- oder Ähnlichkeits-Modellen werden in \citep{linden03} und \citep{Das07} beschrieben. Die Skalierbarkeit und Leistungsfähigkeit der Systeme wird vor allem dadurch möglich, dass komplexe Berechnungen ebenfalls asynchron, d.h. vor der eigentliche Anfrage des Nutzers erfolgen (vgl Abschnitt \ref{sec:scalefiltering}).

\subsubsection{Disjunkte Kanidatenlisten}\label{sec:disjunctcanidates}

%-Wenn man von großen Mengen (großer Raum) von Items ausgeht stellt sich das Problem, das die Teilmenge der Items die der Recommender und die Suche zu einer "Anfrage" zurück geben können disjunkt sein oder nur eine unerhebliche Schnittmenge haben. Teilprobleme wären
%   - "Boosting in der Suchmenge": Recommender bekommt Solr-Menge und macht nur darüber Recommendations (wenn überhaupt möglich - vielleicht kommt man ja in die erste Schleife der user-based algorithmen "i that u has no preference for yet")
%   - "Boosting in der Recommender Menge": Recommender bestimmt Menge (OR query + Optionales query) und Solr boosted nur noch darin. (Use-Case widget)
%   -  "Selective Recommendation": Recommender wählt eine zum Query passendes Datenmodell / Datengrundlage aus, die möglichst viele potentielle Schnittmengen mit dem Query hat
%       - Hier könnte man Jobs haben die regelmäßig die User-Item Datensätze nur für Items lernen die von der Suche zu einem bestimmtem Query zurückkommen (e.g. die Top-Querys)
%   - "Anreicherungsansatz" Der Recommender könnte zu Ergebnissen in der Suchmenge weitere Ergebnisse einstreuen (flgl "More like these" handler).
%   - "Precomputation and Delegation to Solr"


Da beide Bestandteile des Systems zur Erstellung der beschriebenen Anwendungsfälle eigene Problembereiche abdecken, sind die für eine Anfrage generierten Ergebnislisten erwartungsgemäß auch unterschiedlich. Würden beide Systeme vollständig unabhängig voneinander betreiben und abgefragt, wäre die Gefahr groß, dass die Ergebnismengen keine oder nur eine sehr kleine Schnittmenge zur weiteren Verarbeitung generieren würde. Im Anwendungsfall der personalisierten Suche hätte dies zur Folge, dass nur wenige Ergebnisse wirklich entsprechend der Präferenzen des Nutzers bewertet würden und alle weiteren als nicht relevant herabgestuft würden. Anschaulich wird dies zum Beispiel, wenn bei einer Suche nach ``Musicals Hamburg'', wegen der fehlenden inhaltlichen Bindung vom Empfehlungsdienst auf Basis des Nutzerprofiles nur Präferenzen zu anderen Städten oder anderen Veranstaltungstypen gegeben würden. Die Bewertung der vom Suchindex gelieferten Ergebnisse wäre damit nicht möglich. Je spezieller die Suche bzw. Filterung des Nutzers ist, desto kleiner ist die vom Suchindex gefundene Ergebnismenge und umso geringer wäre dann die Wahrscheinlichkeit, eine Schnittmenge zu finden.

Bei den Anwendungsfällen der kontextbasierten Empfehlungen und der Komplementär-Suche besteht das Problem, dass die Größe der möglichen Schnittmengen durch die vordefinierte Filterung des Suchindexes bereits stark eingeschränkt und damit die Wahrscheinlichkeit eine ausreichend große Schnittmenge zwischen beiden Ergebnissmengen zu erhalten von Beginn an sehr gering ist. Auch dieser Fall kann durch das im vorangegangenen Beispiel geschilderte Szenerio leicht erzielt werden. Die vordefinierten Filter der Suche entsprechen dann einer gezielten bzw. speziellen Suche mit den bereits beschriebenen Auswirkungen. Einzig der Anwendungsfall des Cross-Selling ist hiervon nicht betroffen, da hier der Suchindex nur zur Anreicherung der vom Empfehlungsdienst gefundenen Ergebnisse genutzt wird.
%Hierfür muss nur sichergestellt werden, dass beide Systeme auf der gleichen Elementmenge operieren, damit für jede Empfehlung auch tatsächlich inhaltliche Anreicherungen durchgeführt werden können.
% - Recommender empfehlen nur neue Items, man will aber ggf auch das bereits geklickte Items in der Suche höher gewichtet werden (so macht es Google ja auch)

Ein möglicher Ansatz, um den resultierenden Problemen vorzubeugen, ist es, für die beschriebenen Anwendungsfälle jeweils ein führendes System zu wählen. Anstatt eine Anfrage gleichzeitig in beiden Systemen zu verarbeiten, soll die eigentliche Kandidatenliste immer von einem System erstellt werden, um in einem darauf folgenden Schritt vom zweiten weiterverarbeitet zu werden. Für den Anwendungsfall der personalisierten Suche und die kontextbasierten Empfehlungen bedeutet dies, dass der Suchindex als führendes System die Kandidatenliste aufbaut, die dann im weiteren bewertet und umsortiert wird.

Bei Komplementär-Suche und Cross-Selling ist der Emfehlungsdienst das führende System, dessen Ergebnisse durch den Suchindex inhaltlich ergänzt oder gefiltert werden. Können keine oder zuwenige Empfehlungen gefunden werden, ist es in beiden Fällen möglich und akzeptabel Standardelemente zu ergänzen oder die Filter des Suchindexes zu lockern.

Ein weiterer Lösungsansatz ist die Veränderung bzw. Erweiterung der Suchanfragen durch den Empfehlungsdienst (vgl. Abschnitt \ref{sec:personalresultstheorie}). Ähnlich dem von \citep{Boughareb11} gewählten Ansatz, könnte die Anfrage durch die  $n$ wichtigsten Terme der gefundenen Empfehlungen ergänzt werden. In allen Anwendungsfällen, bei denen die Suche als führendes System genutzt wird, würde damit die Anfrage auch direkt zum Mittel der Personalisierung. Da nur der Suchindex eine Ergebnisliste zusammenstellen muss, welche durch die zusätzlichen Terme anders gewichtet wäre, wird das Problem disjunkter Kandidatenlisten vermieden. Die Anwendungsfälle bei denen der Empfehlungsdienst als führendes System dienen muss, könnten ebenfalls über diesen Ansatz gelöst werden, indem die Suchanfrage direkt vom Empfehlungsdienst mit Hilfe der gefundenen Elemente formuliert wird. \newpage %\todo[color=red]{SVD Absatz ergänzen} 

%Die Integration beider Dienste bzw. die Vermeidung getrennter Dienste, wie sie in Abschnitt \ref{sec:myrecommend} beschrieben wird, kann 
% - Da find ich auch Interessant. Man kann sicherlich durch vorclustern ähnlicher Items oder ähnliche Items pro Usercluster alles direkt in einer Abfrage abwickelt  (Durch anreichern der Daten im Index )
%%\todo{ggf. Referenzen zu Smyth05b ergänzen}

\subsubsection{Lern-Laufzeiten}

Eine wichtige Eigenschaft aller in Abschnitt \ref{sec:filtermethods} beschriebenen Methoden ist, dass die vorliegende \textit{User-Item} Matrix genutzt wird, um Modelle der Ähnlichkeiten zwischen Nutzern oder Elementen abzuleiten. Auch wenn die vollständige Neugenerierung der Modelle durch iterative Methoden verhindert werden kann, so müssen neu gewonnene Daten dennoch einen zusätzlichen Schritt durchlaufen, bevor diese Einfluss auf für den Nutzer generierte Empfehlungen haben. Je nach Dauer dieses zusätzlichen Schrittes, kann dies den Nutzen des Systems erheblich beeinflussen. %\todo[color=green]{Iterative Updates bei User/Item based Recommendation ergänzen} 

Aus den notwendigen Aktualisierungen durch neue Daten ergibt sich ein weiterer Nachteil, der vor allem in Lastphasen kritisch ist. Würde man mit jedem Datensatz das Modell (inkrementell) erweitern resultiert daraus, dass immer dann viele Aktualisierungen notwendig würden, wenn der Dienst ohnedies durch viele Nutzer unter Last gesetzt wird. Eine Entlastung, etwa durch das Zwischenspeichern von Ergebnissen, wäre in einer solchen Phase aufgrund des ständig aktualisierten Modells kaum möglich.

In \citep{linden03} wird eine mögliche Strategie beschrieben, um die Auswirkungen des Problems zu verhindern. Da nutzerbasierte Modelle wegen der direkten Bindung an das Verhalten des einzelnen Nutzers stärkeren Schwankungen unterworfen sind, wird die Nutzung der stabileren elementbasierten Modelle vorgeschlagen. Die Stabilität begründet sich vor allem darauf, dass im beschriebenen Fall die Einstellungsänderung einer großen Nutzermenge notwendig ist, um die Ähnlichkeit zwischen Elementen zu beeinflussen. Durch die Nutzung der stabileren Modelle verringert sich die Notwendigkeit, Modelle mit jedem neuen Datensatz neu berechnen zu müssen. Abhängig von Anwendungsfall ergibt sich zudem die Möglichkeit große Teile der Vorberechnung auf zusätzlich vorgehaltener Infrastruktur \textit{offline} zu verrichten ohne die Ressourcen des Empfehlungsdienstes in Anspruch nehmen zu müssen.

Auch der Verzicht auf ein explizites Filtermodell und die Anreicherung der Suchanfrage aus \citep{Boughareb11} stellt eine mögliche Alternative dar. Um dies auf die beschriebenen Anwendungsfälle zu übertragen, könnten die aus den Vorberechnungen des Empfehlungsdienstes gewonnenen Informationen zur Ähnlichkeit zwischen Elementen genutzt werden, um diese entsprechend dieser Elemente zu gruppieren. Die Personalisierung könnte dann abhängig von der Präferenz des Nutzers für die gefundenen Gruppen stattfinden. Die Zwischenergebnisse der Matrixfaktorisierung, vor allem die Werte der $q_i$ Vektoren, könnten in ähnlicher Weise genutzt werden (vgl. Abschnitt \ref{sec:svd} und \ref{sec:myrecommend}). Die Lern-Laufzeiten sind dann bei stabilen Modellen wie in der vorangegangen Lösungsstrategie kein anwendungskritischer Faktor mehr.

%
%http://techblog.netflix.com/2012/06/scalable-logging-and-tracking.html
%LSH
%K. Yu, X. Xu, J. Tao, M. Ester, and H. Kriegel Instance Selection Techniques for Memory-Based Collaborative Filtering In Proc. of the Second Siam Intl. Conf. on Data Mining, (SDM) 2002.
% - Recommendation Algorithmen und Datengrundlage sind sehr verschieden. Wie kann man verschiedene Implementierungen nutzen/ansprechen/auswählen.

